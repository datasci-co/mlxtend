{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sebastian Raschka, 2015  \n",
    "`mlxtend`, a library of extension and helper modules for Python's data analysis and machine learning libraries\n",
    "\n",
    "- GitHub repository: https://github.com/rasbt/mlxtend\n",
    "- Documentation: http://rasbt.github.io/mlxtend/\n",
    "\n",
    "View this page in [jupyter nbviewer](http://nbviewer.ipython.org/github/rasbt/mlxtend/blob/master/docs/sources/_ipynb_templates/math/num_permutations.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sebastian Raschka \n",
      "last updated: 2016-03-06 \n",
      "\n",
      "CPython 3.5.1\n",
      "IPython 4.0.3\n",
      "\n",
      "matplotlib 1.5.1\n",
      "numpy 1.10.4\n",
      "scipy 0.17.0\n",
      "mlxtend 0.3.1.dev0\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a 'Sebastian Raschka' -u -d -v -p matplotlib,numpy,scipy,mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Feature Selector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of *sequential feature algorithms* (SFAs) -- greedy search algorithms -- that have been developed as a suboptimal solution to the computationally often not feasible exhaustive search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> from mlxtend.feature_selection import SequentialFeatureSelector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequential feature selection algorithms are a family of greedy search algorithms that are used to reduce an initial *d*-dimensional feature space to a *k*-dimensional feature subspace where *k < d*. The motivation behind feature selection algorithms is to automatically select a subset of features that is most relevant to the problem. The goal of feature selection is two-fold: We want to improve the computational efficiency and reduce the generalization error of the model by removing irrelevant features or noise. A wrapper approach such as sequential feature selection is especially useful if embedded feeature selection -- for example, a regularization penalty like LASSO -- is not applicable.\n",
    "\n",
    "In a nutshell, SFAs remove or add one feature at the time based on the classifier performance until a feature subset of the desired size *k* is reached. There are 4 different flavors of SFAs available via the `SequentialFeatureSelector`:\n",
    "\n",
    "1. Sequential Forward Selection (SFS)\n",
    "2. Sequential Backward Selection (SBS)\n",
    "3. Sequential Floating Forward Selection (SFFS)\n",
    "4. Sequential Floating Backward Selection (SFBS)\n",
    "\n",
    "The ***floating*** variants, SFFS and SFBS, can be considered as extensions to the simpler SFS and SBS algorithms. The floating algorithms have an additional exclusion or inclusion step to remove features once they were included (or excluded), so that a larger number of feature subset combinations can be sampled. It is important to emphasize that this step is conditional and only occurs if the resulting feature subset is assessed as \"better\" by the criterion function after removal (or addition) of a particular feature. Furthermore, I added an optional check to skip the conditional exclusion steps if the algorithm gets stuck in cycles.  \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "How is this different from *Recursive Feature Elimination* (RFE)  -- e.g., as implemented in `sklearn.feature_selection.RFE`? RFE is computationally less complex using the feature weight coefficients (e.g., linear models) or feature importances (tree-based algorithms) to eliminate features recursively, whereas SFSs eliminate (or add) features based on a user-defined classifier/regression performance metric.\n",
    "\n",
    "---\n",
    "\n",
    "The SFAs  are outlined in pseudo code below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Forward Selection (SFS)\n",
    "\n",
    "\n",
    "**Input:** $Y = \\{y_1, y_2, ..., y_d\\}$  \n",
    "\n",
    "- The ***SFS*** algorithm takes the whole $d$-dimensional feature set as input.\n",
    "\n",
    "\n",
    "**Output:** $X_k = \\{x_j \\; | \\;j = 1, 2, ..., k; \\; x_j \\in Y\\}$, where $k = (0, 1, 2, ..., d)$\n",
    "\n",
    "- SFS returns a subset of features; the number of selected features $k$, where $k < d$, has to be specified *a priori*.\n",
    "\n",
    "**Initialization:** $X_0 = \\emptyset$, $k = 0$\n",
    "\n",
    "- We initialize the algorithm with an empty set $\\emptyset$ (\"null set\") so that $k = 0$ (where $k$ is the size of the subset).\n",
    "\n",
    "**Step 1 (Inclusion):**  \n",
    "\n",
    "  $x^+ = \\text{ arg max } J(x_k + x), \\text{ where }  x \\in Y - X_k$  \n",
    "  $X_k+1 = X_k + x^+$  \n",
    "  $k = k + 1$    \n",
    "  *Go to Step 1* \n",
    "\n",
    "- in this step, we add an additional feature, $x^+$, to our feature subset $X_k$.\n",
    "- $x^+$ is the feature that maximizes our criterion function, that is, the feature that is associated with the best classifier performance if it is added to $X_k$.\n",
    "- We repeat this procedure until the termination criterion is satisfied.\n",
    "\n",
    "**Termination:** $k = p$\n",
    "\n",
    "- We add features from the feature subset $X_k$ until the feature subset of size $k$ contains the number of desired features $p$ that we specified *a priori*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Floating Backward (SBS)\n",
    "\n",
    "**Input:** the set of all features, $Y = \\{y_1, y_2, ..., y_d\\}$  \n",
    "\n",
    "- The SBS algorithm takes the whole feature set as input.\n",
    "\n",
    "**Output:** $X_k = \\{x_j \\; | \\;j = 1, 2, ..., k; \\; x_j \\in Y\\}$, where $k = (0, 1, 2, ..., d)$\n",
    "\n",
    "- SBS returns a subset of features; the number of selected features $k$, where $k < d$, has to be specified *a priori*.\n",
    "\n",
    "**Initialization:** $X_0 = Y$, $k = d$\n",
    "\n",
    "- We initialize the algorithm with the given feature set so that the $k = d$.\n",
    "\n",
    "\n",
    "**Step 1 (Exclusion):**  \n",
    "\n",
    "$x^- = \\text{ arg max } J(x_k - x), \\text{  where } x \\in X_k$  \n",
    "$X_k-1 = X_k - x^-$  \n",
    "$k = k - 1$  \n",
    "*Go to Step 1*  \n",
    "\n",
    "- In this step, we remove a feature, $x^-$ from our feature subset $X_k$.\n",
    "- $x^-$ is the feature that maximizes our criterion function upon re,oval, that is, the feature that is associated with the best classifier performance if it is removed from $X_k$.\n",
    "- We repeat this procedure until the termination criterion is satisfied.\n",
    "\n",
    "\n",
    "**Termination:** $k = p$\n",
    "\n",
    "- We add features from the feature subset $X_k$ until the feature subset of size $k$ contains the number of desired features $p$ that we specified *a priori*.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Floating Backward Selection (SFBS)\n",
    "\n",
    "**Input:** the set of all features, $Y = \\{y_1, y_2, ..., y_d\\}$  \n",
    "\n",
    "- The SFBS algorithm takes the whole feature set as input.\n",
    "\n",
    "**Output:** $X_k = \\{x_j \\; | \\;j = 1, 2, ..., k; \\; x_j \\in Y\\}$, where $k = (0, 1, 2, ..., d)$\n",
    "\n",
    "- SFBS returns a subset of features; the number of selected features $k$, where $k < d$, has to be specified *a priori*.\n",
    "\n",
    "**Initialization:** $X_0 = Y$, $k = d$\n",
    "\n",
    "- We initialize the algorithm with the given feature set so that the $k = d$.\n",
    "\n",
    "**Step 1 (Exclusion):**  \n",
    "\n",
    "$x^- = \\text{ arg max } J(x_k - x), \\text{  where } x \\in X_k$  \n",
    "$X_k-1 = X_k - x^-$  \n",
    "$k = k - 1$  \n",
    "*Go to Step 2*  \n",
    "\n",
    "- In this step, we remove a feature, $x^-$ from our feature subset $X_k$.\n",
    "- $x^-$ is the feature that maximizes our criterion function upon re,oval, that is, the feature that is associated with the best classifier performance if it is removed from $X_k$.\n",
    "\n",
    "\n",
    "**Step 2 (Conditional Inclusion):**  \n",
    "<br>\n",
    "$x^+ = \\text{ arg max } J(x_k + x), \\text{ where } x \\in Y - X_k$  \n",
    "*if J(x_k + x) > J(x_k + x)*:    \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; $X_k+1 = X_k + x^+$  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; $k = k + 1$  \n",
    "*Go to Step 1*  \n",
    "\n",
    "- In Step 2, we search for features that improve the classifier performance if they are added back to the feature subset. If such features exist, we add the feature $x^+$ for which the perfomance improvement is max.\n",
    "- Steps 1 and 2 are reapeated until the **Termination** criterion is reached.\n",
    "\n",
    "**Termination:** $k = p$\n",
    "\n",
    "- We add features from the feature subset $X_k$ until the feature subset of size $k$ contains the number of desired features $p$ that we specified *a priori*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Floating Forward Selection (SFFS)\n",
    "\n",
    "**Input:** the set of all features, $Y = \\{y_1, y_2, ..., y_d\\}$  \n",
    "\n",
    "- The ***SFFS*** algorithm takes the whole feature set as input, if our feature space consists of, e.g. 10, if our feature space consists of 10 dimensions (***d = 10***).\n",
    "<br><br>\n",
    "\n",
    "**Output:** a subset of features, $X_k = \\{x_j \\; | \\;j = 1, 2, ..., k; \\; x_j \\in Y\\}$, where $k = (0, 1, 2, ..., d)$\n",
    "\n",
    "- The returned output of the algorithm is a subset of the feature space of a specified size. E.g., a subset of 5 features from a 10-dimensional feature space (***k = 5, d = 10***).\n",
    "<br><br>\n",
    "\n",
    "**Initialization:** $X_0 = Y$, $k = d$\n",
    "\n",
    "- We initialize the algorithm with an empty set (\"null set\") so that the ***k = 0*** (where ***k*** is the size of the subset)\n",
    "<br><br>\n",
    "\n",
    "**Step 1 (Inclusion):**  \n",
    "<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; $x^+ = \\text{ arg max } J(x_k + x), \\text{ where }  x \\in Y - X_k$  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; $X_k+1 = X_k + x^+$  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; $k = k + 1$    \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;*Go to Step 2*  \n",
    "<br> <br>\n",
    "**Step 2 (Conditional Exclusion):**  \n",
    "<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; $x^- = \\text{ arg max } J(x_k - x), \\text{ where } x \\in X_k$  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;$if \\; J(x_k - x) > J(x_k - x)$:    \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $X_k-1 = X_k - x^- $  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $k = k - 1$    \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;*Go to Step 1*  \n",
    "\n",
    "- In step 1, we include the feature from the ***feature space*** that leads to the best performance increase for our ***feature subset*** (assessed by the ***criterion function***). Then, we go over to step 2\n",
    "- In step 2, we only remove a feature if the resulting subset would gain an increase in performance. We go back to step 1.  \n",
    "- Steps 1 and 2 are reapeated until the **Termination** criterion is reached.\n",
    "<br><br>\n",
    "\n",
    "**Termination:** stop when ***k*** equals the number of desired features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "- Ferri, F., et al. [*\"Comparative study of techniques for large-scale feature selection.\"*](https://books.google.com/books?hl=en&lr=&id=sbajBQAAQBAJ&oi=fnd&pg=PA403&dq=comparative+study+of+techniques+for+large+scale&ots=KdIOYpA8wj&sig=hdOsBP1HX4hcDjx4RLg_chheojc#v=onepage&q=comparative%20study%20of%20techniques%20for%20large%20scale&f=false) Pattern Recognition in Practice IV (1994): 403-413."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1 - A simple Sequential Forward Selection example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing a simple classifier from scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "knn = KNeighborsClassifier(n_neighbors=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by selection the \"best\" 3 features from the Iris dataset via Sequential Forward Selection (SFS). Here, we set `forward=True` and `floating=False`. By choosing `cv=0`, we don't perform any cross-validation, therefore, the performance (here: `'accuracy'`) is computed entirely on the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Features: 3/3"
     ]
    }
   ],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "sfs1 = SFS(knn, \n",
    "           k_features=3, \n",
    "           forward=True, \n",
    "           floating=False, \n",
    "           scoring='accuracy',\n",
    "           cv=0)\n",
    "sfs1 = sfs1.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Via the `subsets_` attribute, we can take a look at the selected feature indices at each step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'avg_score': 0.95999999999999996,\n",
       "  'cv_scores': array([ 0.96]),\n",
       "  'feature_idx': (3,)},\n",
       " 2: {'avg_score': 0.97333333333333338,\n",
       "  'cv_scores': array([ 0.97333333]),\n",
       "  'feature_idx': (2, 3)},\n",
       " 3: {'avg_score': 0.97333333333333338,\n",
       "  'cv_scores': array([ 0.97333333]),\n",
       "  'feature_idx': (1, 2, 3)}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfs1.subsets_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, we can access the indices of the 3 best features directly via the `k_feature_idx_` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfs1.k_feature_idx_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the prediction score for these 3 features can be accesses via `k_score_`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97333333333333338"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfs1.k_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2 - Toggling between SFS, SBS, SFFS, and SFBS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `forward` and `floating` parameters, we can toggle between SFS, SBS, SFFS, and SFBS as shown below. Note that we are performing (stratified) 4-fold cross-validation for more robust estimates in contrast to Example 1. Via `n_jobs=-1`, we choose to run the cross-validation on all our available CPU cores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sequential Forward Selection (k=3):\n",
      "(1, 2, 3)\n",
      "CV Score:\n",
      "0.972756410256\n",
      "\n",
      "Sequential Backward Selection (k=3):\n",
      "(1, 2, 3)\n",
      "CV Score:\n",
      "0.972756410256\n",
      "\n",
      "Sequential Floating Forward Selection (k=3):\n",
      "(1, 2, 3)\n",
      "CV Score:\n",
      "0.972756410256\n",
      "\n",
      "Sequential Floating Backward Selection (k=3):\n",
      "(1, 2, 3)\n",
      "CV Score:\n",
      "0.972756410256\n"
     ]
    }
   ],
   "source": [
    "# Sequential Forward Selection\n",
    "sfs = SFS(knn, \n",
    "          k_features=3, \n",
    "          forward=True, \n",
    "          floating=False, \n",
    "          scoring='accuracy',\n",
    "          print_progress=False,\n",
    "          cv=4,\n",
    "          n_jobs=-1)\n",
    "sfs = sfs.fit(X, y)\n",
    "\n",
    "print('\\nSequential Forward Selection (k=3):')\n",
    "print(sfs.k_feature_idx_)\n",
    "print('CV Score:')\n",
    "print(sfs.k_score_)\n",
    "\n",
    "###################################################\n",
    "\n",
    "# Sequential Backward Selection\n",
    "sbs = SFS(knn, \n",
    "          k_features=3, \n",
    "          forward=False, \n",
    "          floating=False, \n",
    "          scoring='accuracy',\n",
    "          print_progress=False,\n",
    "          cv=4,\n",
    "          n_jobs=-1)\n",
    "sbs = sbs.fit(X, y)\n",
    "\n",
    "print('\\nSequential Backward Selection (k=3):')\n",
    "print(sbs.k_feature_idx_)\n",
    "print('CV Score:')\n",
    "print(sbs.k_score_)\n",
    "\n",
    "###################################################\n",
    "\n",
    "# Sequential Floating Forward Selection\n",
    "sffs = SFS(knn, \n",
    "           k_features=3, \n",
    "           forward=True, \n",
    "           floating=True, \n",
    "           scoring='accuracy',\n",
    "           print_progress=False,\n",
    "           cv=4,\n",
    "           n_jobs=-1)\n",
    "sffs = sffs.fit(X, y)\n",
    "\n",
    "print('\\nSequential Floating Forward Selection (k=3):')\n",
    "print(sffs.k_feature_idx_)\n",
    "print('CV Score:')\n",
    "print(sffs.k_score_)\n",
    "\n",
    "###################################################\n",
    "\n",
    "# Sequential Floating Backward Selection\n",
    "sfbs = SFS(knn, \n",
    "           k_features=3, \n",
    "           forward=False, \n",
    "           floating=True, \n",
    "           scoring='accuracy',\n",
    "           print_progress=False,\n",
    "           cv=4,\n",
    "           n_jobs=-1)\n",
    "sfbs = sfbs.fit(X, y)\n",
    "\n",
    "print('\\nSequential Floating Backward Selection (k=3):')\n",
    "print(sfbs.k_feature_idx_)\n",
    "print('CV Score:')\n",
    "print(sfbs.k_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this simple scenario, selecting the best 3 features out of the 4 available features in the Iris set, we end up with similar results regardless of which sequential selection algorithms we used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3 - Visualizing the results in DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " For our convenience, we can visualize the output from the feature selection in a pandas DataFrame format using the `get_metric_dict` method of the SequentialFeatureSelector object. The columns `std_dev` and `std_err` represent the standard deviation and standard errors of the cross-validation scores, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we see the DataFrame of the Sequential Forward Selector from Example 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_score</th>\n",
       "      <th>ci_bound</th>\n",
       "      <th>cv_scores</th>\n",
       "      <th>feature_idx</th>\n",
       "      <th>std_dev</th>\n",
       "      <th>std_err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.0660624</td>\n",
       "      <td>[0.974358974359, 0.948717948718, 0.88888888888...</td>\n",
       "      <td>(3,)</td>\n",
       "      <td>0.0412122</td>\n",
       "      <td>0.0237939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.959936</td>\n",
       "      <td>0.0494801</td>\n",
       "      <td>[0.974358974359, 0.948717948718, 0.91666666666...</td>\n",
       "      <td>(2, 3)</td>\n",
       "      <td>0.0308676</td>\n",
       "      <td>0.0178214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.972756</td>\n",
       "      <td>0.0315204</td>\n",
       "      <td>[0.974358974359, 1.0, 0.944444444444, 0.972222...</td>\n",
       "      <td>(1, 2, 3)</td>\n",
       "      <td>0.0196636</td>\n",
       "      <td>0.0113528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  avg_score   ci_bound                                          cv_scores  \\\n",
       "1  0.952991  0.0660624  [0.974358974359, 0.948717948718, 0.88888888888...   \n",
       "2  0.959936  0.0494801  [0.974358974359, 0.948717948718, 0.91666666666...   \n",
       "3  0.972756  0.0315204  [0.974358974359, 1.0, 0.944444444444, 0.972222...   \n",
       "\n",
       "  feature_idx    std_dev    std_err  \n",
       "1        (3,)  0.0412122  0.0237939  \n",
       "2      (2, 3)  0.0308676  0.0178214  \n",
       "3   (1, 2, 3)  0.0196636  0.0113528  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame.from_dict(sfs.get_metric_dict()).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's compare it to the Sequential Backward Selector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_score</th>\n",
       "      <th>ci_bound</th>\n",
       "      <th>cv_scores</th>\n",
       "      <th>feature_idx</th>\n",
       "      <th>std_dev</th>\n",
       "      <th>std_err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.972756</td>\n",
       "      <td>0.0315204</td>\n",
       "      <td>[0.974358974359, 1.0, 0.944444444444, 0.972222...</td>\n",
       "      <td>(1, 2, 3)</td>\n",
       "      <td>0.0196636</td>\n",
       "      <td>0.0113528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.0372857</td>\n",
       "      <td>[0.974358974359, 0.948717948718, 0.91666666666...</td>\n",
       "      <td>(0, 1, 2, 3)</td>\n",
       "      <td>0.0232602</td>\n",
       "      <td>0.0134293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  avg_score   ci_bound                                          cv_scores  \\\n",
       "3  0.972756  0.0315204  [0.974358974359, 1.0, 0.944444444444, 0.972222...   \n",
       "4  0.952991  0.0372857  [0.974358974359, 0.948717948718, 0.91666666666...   \n",
       "\n",
       "    feature_idx    std_dev    std_err  \n",
       "3     (1, 2, 3)  0.0196636  0.0113528  \n",
       "4  (0, 1, 2, 3)  0.0232602  0.0134293  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(sbs.get_metric_dict()).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that both SFS and SFBS found the same \"best\" 3 features, however, the intermediate steps where obviously different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ci_bound` column in the DataFrames above represents the confidence interval around the computed cross-validation scores. By default, a confidence interval of 95% is used, but we can use different confidence bounds via the `confidence_interval` parameter. E.g., the confidence bounds for a 90% confidence interval can be obtained as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_score</th>\n",
       "      <th>ci_bound</th>\n",
       "      <th>cv_scores</th>\n",
       "      <th>feature_idx</th>\n",
       "      <th>std_dev</th>\n",
       "      <th>std_err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.972756</td>\n",
       "      <td>0.0242024</td>\n",
       "      <td>[0.974358974359, 1.0, 0.944444444444, 0.972222...</td>\n",
       "      <td>(1, 2, 3)</td>\n",
       "      <td>0.0196636</td>\n",
       "      <td>0.0113528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.0286292</td>\n",
       "      <td>[0.974358974359, 0.948717948718, 0.91666666666...</td>\n",
       "      <td>(0, 1, 2, 3)</td>\n",
       "      <td>0.0232602</td>\n",
       "      <td>0.0134293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  avg_score   ci_bound                                          cv_scores  \\\n",
       "3  0.972756  0.0242024  [0.974358974359, 1.0, 0.944444444444, 0.972222...   \n",
       "4  0.952991  0.0286292  [0.974358974359, 0.948717948718, 0.91666666666...   \n",
       "\n",
       "    feature_idx    std_dev    std_err  \n",
       "3     (1, 2, 3)  0.0196636  0.0113528  \n",
       "4  (0, 1, 2, 3)  0.0232602  0.0134293  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(sbs.get_metric_dict(confidence_interval=0.90)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4 - Plotting the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After importing the little helper function `plot_sequential_feature_selection`, we can also visualize the results using matplotlib figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Features: 4/4"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEZCAYAAABiu9n+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10bbae438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mlxtend.feature_selection import plot_sequential_feature_selection as plot_sfs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sfs = SFS(knn, \n",
    "          k_features=4, \n",
    "          forward=True, \n",
    "          floating=False, \n",
    "          scoring='accuracy',\n",
    "          cv=5)\n",
    "\n",
    "sfs = sfs.fit(X, y)\n",
    "\n",
    "fig1 = plot_sfs(sfs.get_metric_dict(), kind='std_dev')\n",
    "\n",
    "plt.ylim([0.8, 1])\n",
    "plt.title('Sequential Forward Selection (w. StdDev)')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5 - Sequential Feature Selection for Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the classification examples above, the `SequentialFeatureSelector` also supports scikit-learn's estimators\n",
    "for regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Features: 13/13"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEZCAYAAAB4hzlwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmIp/AFAVGPakAr96AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10bbae400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()\n",
    "X, y = boston.data, boston.target\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "sfs = SFS(lr, \n",
    "          k_features=13, \n",
    "          forward=True, \n",
    "          floating=False, \n",
    "          scoring='mean_squared_error',\n",
    "          cv=10)\n",
    "\n",
    "sfs = sfs.fit(X, y)\n",
    "fig = plot_sfs(sfs.get_metric_dict(), kind='std_err')\n",
    "\n",
    "plt.title('Sequential Forward Selection (w. StdDev)')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Example 6 -- Using the Selected Feature Subset For Making New Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize the dataset\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "         X, y, test_size=0.33, random_state=1)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Features: 3/3"
     ]
    }
   ],
   "source": [
    "# Select the \"best\" three features via\n",
    "# 5-fold cross-validation on the training set.\n",
    "\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "sfs1 = SFS(knn, \n",
    "           k_features=3, \n",
    "           forward=True, \n",
    "           floating=False, \n",
    "           scoring='accuracy',\n",
    "           cv=5)\n",
    "sfs1 = sfs1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: (1, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "print('Selected features:', sfs1.k_feature_idx_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 96.00 %\n"
     ]
    }
   ],
   "source": [
    "# Generate the new subsets based on the selected features\n",
    "# Note that the transform call is equivalent to\n",
    "# X_train[:, sfs1.k_feature_idx_]\n",
    "\n",
    "X_train_sfs = sfs1.transform(X_train)\n",
    "X_test_sfs = sfs1.transform(X_test)\n",
    "\n",
    "# Fit the estimator using the new feature subset\n",
    "# and make a prediction on the test data\n",
    "knn.fit(X_train_sfs, y_train)\n",
    "y_pred = knn.predict(X_test_sfs)\n",
    "\n",
    "# Compute the accuracy of the prediction\n",
    "acc = float((y_test == y_pred).sum()) / y_pred.shape[0]\n",
    "print('Test set accuracy: %.2f %%' % (acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 7 -- Sequential Feature Selection and GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize the dataset\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "         X, y, test_size=0.33, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use scikit-learn's `GridSearch` to tune the hyperparameters inside and outside the `SequentialFeatureSelector`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:    2.7s\n",
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:    4.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "import mlxtend\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "\n",
    "sfs1 = SFS(estimator=knn, \n",
    "           k_features=3,\n",
    "           forward=True, \n",
    "           floating=False, \n",
    "           scoring='accuracy',\n",
    "           print_progress=False,\n",
    "           cv=5)\n",
    "\n",
    "pipe = Pipeline([('sfs', sfs1), \n",
    "                 ('knn', knn)])\n",
    "\n",
    "param_grid = [\n",
    "  {'sfs__k_features': [1, 2, 3, 4],\n",
    "   'sfs__estimator__n_neighbors': [1, 2, 3, 4]}\n",
    "  ]\n",
    "    \n",
    "gs = GridSearchCV(estimator=pipe, \n",
    "                  param_grid=param_grid, \n",
    "                  scoring='accuracy', \n",
    "                  n_jobs=1, \n",
    "                  cv=5, \n",
    "                  verbose=1, \n",
    "                  refit=False)\n",
    "\n",
    "# run gridearch\n",
    "gs = gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and the \"best\" parameters determined by GridSearch are ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters via GridSearch {'sfs__estimator__n_neighbors': 2, 'sfs__k_features': 3}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters via GridSearch\", gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## SequentialFeatureSelector\n",
      "\n",
      "*SequentialFeatureSelector(estimator, k_features, forward=True, floating=False, print_progress=True, scoring='accuracy', cv=5, skip_if_stuck=True, n_jobs=1, pre_dispatch='2*n_jobs')*\n",
      "\n",
      "Sequential Feature Selection for Classification and Regression.\n",
      "\n",
      "**Parameters**\n",
      "\n",
      "- `estimator` : scikit-learn classifier or regressor\n",
      "\n",
      "\n",
      "- `k_features` : int\n",
      "\n",
      "    Number of features to select,\n",
      "    where k_features < the full feature set.\n",
      "\n",
      "- `forward` : bool (default: True)\n",
      "\n",
      "    Forward selection if True,\n",
      "    backward selection otherwise\n",
      "\n",
      "- `floating` : bool (default: False)\n",
      "\n",
      "    Adds a conditional exclusion/inclusion if True.\n",
      "\n",
      "- `print_progress` : bool (default: True)\n",
      "\n",
      "    Prints progress as the number of epochs\n",
      "    to stderr.\n",
      "\n",
      "- `scoring` : str, (default='accuracy')\n",
      "\n",
      "    Scoring metric in {accuracy, f1, precision, recall, roc_auc}\n",
      "    for classifiers,\n",
      "    {'mean_absolute_error', 'mean_squared_error',\n",
      "    'median_absolute_error', 'r2'} for regressors,\n",
      "    or a callable object or function with\n",
      "    signature ``scorer(estimator, X, y)``.\n",
      "\n",
      "- `cv` : int (default: 5)\n",
      "\n",
      "    Scikit-learn cross-validation generator or `int`.\n",
      "    If estimator is a classifier (or y consists of integer class labels),\n",
      "    stratified k-fold is performed, and regular k-fold cross-validation\n",
      "    otherwise.\n",
      "    No cross-validation if cv is None, False, or 0.\n",
      "    skip_if_stuck: bool (default: True)\n",
      "    Set to True to skip conditional\n",
      "    exlusion/inclusion if floating=True and\n",
      "    algorithm gets stuck in cycles.\n",
      "\n",
      "- `n_jobs` : int (default: 1)\n",
      "\n",
      "    The number of CPUs to use for cross validation. -1 means 'all CPUs'.\n",
      "\n",
      "- `pre_dispatch` : int, or string (default: '2*n_jobs')\n",
      "\n",
      "    Controls the number of jobs that get dispatched\n",
      "    during parallel execution in cross_val_score.\n",
      "    Reducing this number can be useful to avoid an explosion of\n",
      "    memory consumption when more jobs get dispatched than CPUs can process.\n",
      "    This parameter can be:\n",
      "    None, in which case all the jobs are immediately created and spawned.\n",
      "    Use this for lightweight and fast-running jobs,\n",
      "    to avoid delays due to on-demand spawning of the jobs\n",
      "    An int, giving the exact number of total jobs that are spawned\n",
      "    A string, giving an expression as a function\n",
      "    of n_jobs, as in `'2*n_jobs'`\n",
      "\n",
      "**Attributes**\n",
      "\n",
      "- `k_feature_idx_` : array-like, shape = [n_predictions]\n",
      "\n",
      "    Feature Indices of the selected feature subsets.\n",
      "\n",
      "- `k_score_` : float\n",
      "\n",
      "    Cross validation average score of the selected subset.\n",
      "\n",
      "- `subsets_` : dict\n",
      "\n",
      "    A dictionary of selected feature subsets during the\n",
      "    sequential selection, where the dictionary keys are\n",
      "    the lenghts k of these feature subsets. The dictionary\n",
      "    values are dictionaries themselves with the following\n",
      "    keys: 'feature_idx' (tuple of indices of the feature subset)\n",
      "    'cv_scores' (list individual cross-validation scores)\n",
      "    'avg_score' (average cross-validation score)\n",
      "\n",
      "### Methods\n",
      "\n",
      "<hr>\n",
      "\n",
      "*fit(X, y)*\n",
      "\n",
      "None\n",
      "\n",
      "<hr>\n",
      "\n",
      "*fit_transform(X, y)*\n",
      "\n",
      "None\n",
      "\n",
      "<hr>\n",
      "\n",
      "*get_metric_dict(confidence_interval=0.95)*\n",
      "\n",
      "None\n",
      "\n",
      "<hr>\n",
      "\n",
      "*get_params(deep=True)*\n",
      "\n",
      "Get parameters for this estimator.\n",
      "\n",
      "**Parameters**\n",
      "\n",
      "deep: boolean, optional\n",
      "    If True, will return the parameters for this estimator and\n",
      "    contained subobjects that are estimators.\n",
      "\n",
      "**Returns**\n",
      "\n",
      "- `params` : mapping of string to any\n",
      "\n",
      "    Parameter names mapped to their values.\n",
      "\n",
      "<hr>\n",
      "\n",
      "*set_params(**params)*\n",
      "\n",
      "Set the parameters of this estimator.\n",
      "\n",
      "    The method works on simple estimators as well as on nested objects\n",
      "    (such as pipelines). The former have parameters of the form\n",
      "    ``<component>__<parameter>`` so that it's possible to update each\n",
      "    component of a nested object.\n",
      "\n",
      "**Returns**\n",
      "\n",
      "self\n",
      "\n",
      "<hr>\n",
      "\n",
      "*transform(X)*\n",
      "\n",
      "None\n",
      "\n",
      "<br><br>\n",
      "*plot_sequential_feature_selection(metric_dict, kind='std_dev', color='blue', bcolor='steelblue', marker='o', alpha=0.2, ylabel='Performance', confidence_interval=0.95)*\n",
      "\n",
      "Plot sequential feature selection.\n",
      "\n",
      "**Parameters**\n",
      "\n",
      "- `metric_dict` : mlxtend.SequentialFeatureSelector.get_metric_dict() object\n",
      "\n",
      "\n",
      "- `kind` : str (default: \"std_dev\")\n",
      "\n",
      "    The kind of error bar or confidence interval in\n",
      "    {'std_dev', 'std_err', 'ci', None}.\n",
      "\n",
      "- `color` : str (default: \"blue\")\n",
      "\n",
      "    Color of the lineplot (accepts any matplotlib color name)\n",
      "\n",
      "- `bcolor` : str (default: \"steelblue\").\n",
      "\n",
      "    Color of the error bars / confidence intervals\n",
      "    (accepts any matplotlib color name).\n",
      "\n",
      "- `marker` : str (default: \"o\")\n",
      "\n",
      "    Marker of the line plot\n",
      "    (accepts any matplotlib marker name).\n",
      "\n",
      "- `alpha` : float in [0, 1] (default: 0.2)\n",
      "\n",
      "    Transparency of the error bars / confidence intervals.\n",
      "\n",
      "- `ylabel` : str (default: \"Performance\")\n",
      "\n",
      "    Y-axis label.\n",
      "\n",
      "- `confidence_interval` : float (default: 0.95)\n",
      "\n",
      "    Confidence level if `kind='ci'`.\n",
      "\n",
      "**Returns**\n",
      "\n",
      "- `fig` : matplotlib.pyplot.figure() object\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('../../api_modules/mlxtend.feature_selection/SequentialFeatureSelector.md', 'r') as f:\n",
    "    s = f.read() + '<br><br>'\n",
    "\n",
    "with open('../../api_modules/mlxtend.feature_selection/plot_sequential_feature_selection.md', 'r') as f:\n",
    "    s2 = f.readlines()\n",
    "    s += ''.join(s2[1:])\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
